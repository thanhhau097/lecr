{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30fa54d8-22bc-4134-9fff-bf6c8120ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install annoy\n",
    "# import os\n",
    "# # print(os.environ[\"LD_LIBRARY_PATH\"])\n",
    "# os.environ[\"LD_LIBRARY_PATH\"] = \"/opt/conda/lib/python3.8/site-packages/torch/lib:/usr/local/cuda-11.3/lib64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbebda6-bd0f-418f-92f4-a2839c8155b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text\n",
    "# from textblob import TextBlob\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "def decontracted(phrase):\n",
    "\n",
    "    # Specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    # ..\n",
    "\n",
    "    # General\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    # ..\n",
    "\n",
    "    return phrase\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in list(string.punctuation): text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "def clean_number(text):\n",
    "    text = re.sub(r'(\\d+)([a-zA-Z])', '\\g<1> \\g<2>', text)\n",
    "    text = re.sub(r'(\\d+) (th|st|nd|rd) ', '\\g<1>\\g<2> ', text)\n",
    "    text = re.sub(r'(\\d+),(\\d+)', '\\g<1>\\g<2>', text)\n",
    "    return text\n",
    "\n",
    "def clean_whitespace(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def clean_repeat_words(text):\n",
    "    return re.sub(r\"(\\w*)(\\w)\\2(\\w*)\", r\"\\1\\2\\3\", text)\n",
    "\n",
    "def clean_text(text):\n",
    "    # text_blob = TextBlob(text)\n",
    "    # text = str(text_blob.correct())\n",
    "    text = str(text)\n",
    "    text = decontracted(text)\n",
    "    text = remove_punctuations(text)\n",
    "    text = clean_number(text)\n",
    "    text = clean_whitespace(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96a1dd2-a3b5-40ec-87e6-4231794a3bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from dataset import AutoTokenizer, LANGUAGE_TOKENS, CATEGORY_TOKENS, LEVEL_TOKENS, KIND_TOKENS, OTHER_TOKENS\n",
    "from model import Model\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, default_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45499b1d-2636-4ffd-9d4f-e578ce45e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "TEST_MODE = False\n",
    "\n",
    "# --------------------- VALIDATION SET --------------------------\n",
    "from tqdm import tqdm\n",
    "if not TEST_MODE:\n",
    "    data_df = pd.read_csv(\"./data/supervised_correlations.csv\")\n",
    "    fold = 0\n",
    "val_topic_ids = list(data_df[data_df[\"fold\"] == fold].topics_ids)\n",
    "del data_df\n",
    "\n",
    "data_folder = Path(\"./data\")\n",
    "# TODO: we have to process for test set ourselves\n",
    "contents_df = pd.read_csv(data_folder/'content.csv')\n",
    "contents_df = contents_df.fillna('')\n",
    "contents_df['title_len'] = contents_df.title.str.len()\n",
    "contents_df = contents_df.sort_values(by='title_len', axis=0).reset_index(drop=True).drop(columns=['title_len'])\n",
    "topics_df = pd.read_csv(data_folder/'topics.csv')\n",
    "topics_df = topics_df.fillna('')\n",
    "topics_df['title_len'] = topics_df.title.str.len()\n",
    "topics_df = topics_df.sort_values(by='title_len', axis=0).reset_index(drop=True).drop(columns=['title_len'])\n",
    "subs_df = pd.read_csv(data_folder/'sample_submission.csv')\n",
    "corrs_df = pd.read_csv(data_folder/'correlations.csv')\n",
    "\n",
    "\n",
    "topics_df[\"title\"] = topics_df[\"title\"].apply(clean_text)\n",
    "topics_df[\"description\"] = topics_df[\"description\"].apply(clean_text)\n",
    "\n",
    "contents_df[\"title\"] = contents_df[\"title\"].apply(clean_text)\n",
    "contents_df[\"description\"] = contents_df[\"description\"].apply(clean_text)\n",
    "# contents_df[\"text\"] = contents_df[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "455b4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised_correlations = pd.read_csv(\"data/supervised_correlations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d02882b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised_correlations[(supervised_correlations[\"topics_ids\"].isin(val_topic_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "356ea076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised_correlations[(supervised_correlations[\"topics_ids\"].isin(val_topic_ids)) & (supervised_correlations[\"target\"] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82366c3e-915e-4dc6-9926-305514f27a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6152it [00:00, 26388.69it/s]\n",
      "154047it [00:05, 29199.99it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "if TEST_MODE:\n",
    "    topics_df = topics_df[topics_df.id.isin(subs_df.topic_id)]\n",
    "else: # VAL_MODE\n",
    "    topics_df = topics_df[topics_df.id.isin(val_topic_ids)]\n",
    "\n",
    "topic_dict = {}\n",
    "for i, (index, row) in tqdm(enumerate(topics_df.iterrows())):\n",
    "    text = \"<|topic|>\" + f\"<|lang_{row['language']}|>\" + f\"<|category_{row['category']}|>\" + f\"<|level_{row['level']}|>\"\n",
    "    text += \"<s_title>\" + row[\"title\"] + \"</s_title>\" + \"<s_description>\" + row[\"description\"] + \"</s_description>\"\n",
    "    topic_dict[row[\"id\"]] = text\n",
    "\n",
    "content_dict = {}\n",
    "for i, (index, row) in tqdm(enumerate(contents_df.iterrows())):\n",
    "    text = \"<|content|>\" + f\"<|lang_{row['language']}|>\" + f\"<|kind_{row['kind']}|>\"\n",
    "    text += \"<s_title>\" + row[\"title\"] + \"</s_title>\" + \"<s_description>\" + row[\"description\"] + \"</s_description>\" # + \"<s_text>\" + row[\"text\"] + \"</s_text>\"\n",
    "    content_dict[row[\"id\"]] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2782f1a-36d1-4b5a-89b6-926aeed6541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df[\"topic_text\"] = topic_dict.values()\n",
    "topics_df[\"topic_text\"] = topics_df[\"topic_text\"] # .apply(lambda x: x[:2048])\n",
    "\n",
    "contents_df[\"content_text\"] = content_dict.values()\n",
    "contents_df[\"content_text\"] = contents_df[\"content_text\"] # .apply(lambda x: x[:2048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd58ee0-c996-4b14-9c3b-7d22847dc8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer_name='xlm-roberta-base', max_len=512):\n",
    "        self.texts = texts\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.tokenizer.add_special_tokens(dict(additional_special_tokens=LANGUAGE_TOKENS + CATEGORY_TOKENS + LEVEL_TOKENS + KIND_TOKENS + OTHER_TOKENS))\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        \n",
    "        # topic\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, \n",
    "            return_tensors = None, \n",
    "            add_special_tokens = True, \n",
    "            max_length = self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation = True\n",
    "        )\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "            \n",
    "        return inputs\n",
    "    \n",
    "def collate_fn(inputs):\n",
    "    inputs = default_collate(inputs)\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "        \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09637446-9ae8-4a8b-b60e-629097b0d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dataset = InferenceDataset(texts=list(topics_df.topic_text.values), tokenizer_name='sentence-transformers/all-MiniLM-L6-v2', max_len=128)\n",
    "topic_dataloader = DataLoader(topic_dataset, batch_size=256, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "997d32b1-318b-4424-af01-bbf075298558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Model(tokenizer_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_name=\"sentence-transformers/all-MiniLM-L6-v2\", objective=\"both\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "weights_path = \"./outputs_siamese/checkpoint-76752/pytorch_model.bin\"\n",
    "\n",
    "state_dict = torch.load(weights_path)\n",
    "new_state_dict = {}\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith(\"model.\"):\n",
    "        new_k = k[6:]\n",
    "        new_state_dict[new_k] = v\n",
    "\n",
    "model.model.load_state_dict(new_state_dict)\n",
    "\n",
    "if \"fc.weight\" in state_dict:\n",
    "    model.fc.load_state_dict({\n",
    "        \"weight\": state_dict[\"fc.weight\"],\n",
    "        \"bias\": state_dict[\"fc.bias\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30f33aac-6b81-4c11-9855-4e627d36b2ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  8.25it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "topic_embs = []\n",
    "\n",
    "for inputs in tqdm(topic_dataloader):\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k].to(device)\n",
    "    out = model.feature(inputs)\n",
    "    topic_embs.extend(out.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37f63849-09ae-43c5-bb5b-1bdbcba33f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 602/602 [01:03<00:00,  9.47it/s]\n"
     ]
    }
   ],
   "source": [
    "content_dataset = InferenceDataset(texts=list(contents_df.content_text.values), tokenizer_name='sentence-transformers/all-MiniLM-L6-v2', max_len=128)\n",
    "content_dataloader = DataLoader(content_dataset, batch_size=256, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# # \n",
    "# del contents_df[\"text\"]\n",
    "# del contents_df\n",
    "\n",
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    "content_embs = []\n",
    "\n",
    "for inputs in tqdm(content_dataloader):\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k].to(device)\n",
    "    out = model.feature(inputs)\n",
    "    content_embs.extend(out.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a621519-5667-4375-bfaf-4212315d6330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load from saved files\n",
    "# torch.save(topic_embs, \"./data/topic_embs.pt\")\n",
    "# torch.save(content_embs, \"./data/content_embs.pt\")\n",
    "\n",
    "# # topic_embs = torch.load(\"./data/topic_embs.pt\")\n",
    "# # content_embs = torch.load(\"./data/content_embs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f341bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fuzzywuzzy annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3fb7ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_content_embs = []\n",
    "# for emb in tqdm(content_embs):\n",
    "#     normalized_content_embs.append(F.normalize(torch.from_numpy(emb), p=2, dim=0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6823d481-81c7-4038-be02-4cced8eee0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 154047/154047 [00:05<00:00, 28546.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "\n",
    "content_forest = AnnoyIndex(content_embs[0].shape[0], metric='angular')\n",
    "for i, item in tqdm(enumerate(content_embs), total=len(content_embs)):\n",
    "    content_forest.add_item(i, item)\n",
    "content_forest.build(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cda876a8-cfb2-4697-88d7-e313f3a1669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics = topics_df[topics_df.has_content==True][['id', 'title', 'language']].reset_index(drop=True)\n",
    "\n",
    "topics = topics_df\n",
    "\n",
    "test = topics\n",
    "all_content_ids = contents_df.id.to_numpy()\n",
    "all_content_titles = contents_df.title.to_numpy()\n",
    "all_content_language = contents_df.language.to_numpy()\n",
    "all_test_ids = list(topics.id)\n",
    "all_test_title = list(topics.title)\n",
    "all_test_language = list(test.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7a11b16-c327-4ce4-9b38-f3e3bec2d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_forest.get_nns_by_vector(topic_embs[5], 10, include_distances=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b24495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_dict = {}\n",
    "fuzzy_dict = {}\n",
    "classification_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4596424-e963-48fd-8f4a-627e77f82c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Preds: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6152/6152 [01:01<00:00, 100.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuzzy_filter 80 THRESHOLD: 0 f2_score 0.0219\n"
     ]
    }
   ],
   "source": [
    "# TODO: find by distance instead\n",
    "\n",
    "nearest_content_count = 500\n",
    "fuzzy_filter = 80\n",
    "THRESHOLD = 0\n",
    "# for fuzzy_filter in range(5, 50, 5):\n",
    "#     for t in range(1, 10, 2):\n",
    "#         THRESHOLD = t / 100\n",
    "preds = []\n",
    "for i, t_e in tqdm(enumerate(topic_embs), total=len(topic_embs), desc=f'Getting Preds'):\n",
    "    if i in indexes_dict:\n",
    "        indexes, distances = indexes_dict[i]\n",
    "    else:\n",
    "        indexes, distances = content_forest.get_nns_by_vector(\n",
    "            # F.normalize(torch.from_numpy(t_e), p=2, dim=0),\n",
    "            t_e,\n",
    "            nearest_content_count,\n",
    "            include_distances=True\n",
    "        )\n",
    "        # indexes = [i for i, d in zip(indexes, distances) if d < 10]\n",
    "        indexes_dict[i] = indexes, distances\n",
    "\n",
    "    topic_id = all_test_ids[i]\n",
    "    topic_text = all_test_title[i]\n",
    "    topic_lang = all_test_language[i]\n",
    "\n",
    "    # for idx in indexes:\n",
    "    #     if topic_lang != all_content_language[idx]:\n",
    "    #         indexes.remove(idx)\n",
    "    \n",
    "    # filtered_indexes = []\n",
    "    # for idx in indexes:\n",
    "    #     if topic_lang != all_content_language[idx]:\n",
    "    #         continue\n",
    "    #     if (i, idx) in fuzzy_dict:\n",
    "    #         fuzzy_value = fuzzy_dict[(i, idx)]\n",
    "    #     else:\n",
    "    #         fuzzy_value = fuzz.token_set_ratio(all_content_titles[idx], topic_text)\n",
    "    #         fuzzy_dict[(i, idx)] = fuzzy_value\n",
    "        \n",
    "    #     if fuzzy_value > fuzzy_filter:\n",
    "    #         filtered_indexes.append(idx)\n",
    "        \n",
    "    #     if (i, idx) in classification_dict:\n",
    "    #         score = classification_dict[(i, idx)]\n",
    "    #     else:\n",
    "    #         topic_features = torch.from_numpy(t_e).to(device)\n",
    "    #         content_features = torch.from_numpy(content_embs[idx]).to(device)\n",
    "    #         score = torch.sigmoid(model.fc(torch.cat([topic_features, content_features, topic_features - content_features], -1))).item()\n",
    "    #         classification_dict[(i, idx)] = score\n",
    "    #     if score < THRESHOLD and idx in filtered_indexes:\n",
    "    #         filtered_indexes.remove(idx)\n",
    "    # ind2dis = {ind: d for ind, d in zip(indexes, distances)}\n",
    "    # if len(filtered_indexes) == 0:\n",
    "    #     indexes = filtered_indexes[:8] # list(set(filtered_indexes + indexes[:8-len(filtered_indexes)]))\n",
    "    # else:\n",
    "    #     indexes = filtered_indexes[:8]\n",
    "    content_ids = all_content_ids[indexes]\n",
    "    preds.append({\n",
    "        'topic_id': topic_id,\n",
    "        'content_ids': ' '.join(content_ids),\n",
    "        # 'distances': ' '.join([str(ind2dis[ind]) for ind in indexes]),\n",
    "    })\n",
    "preds = pd.DataFrame.from_records(preds)\n",
    "\n",
    "preds.to_csv('submission.csv', index=False)\n",
    "\n",
    "if not TEST_MODE:\n",
    "    from engine import f2_score\n",
    "    gt = corrs_df[corrs_df.topic_id.isin(val_topic_ids)].sort_values(\"topic_id\")    \n",
    "    preds = preds.sort_values(\"topic_id\")    \n",
    "    print(\"fuzzy_filter\", fuzzy_filter, \"THRESHOLD:\", THRESHOLD, \"f2_score\", f2_score(gt[\"content_ids\"], preds[\"content_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76089c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_pos_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    int_true = np.array([len(x[0] & x[1]) / len(x[0]) for x in zip(y_true, y_pred)])\n",
    "    return round(np.mean(int_true), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2466ea17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56501"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pos_score(gt[\"content_ids\"], preds[\"content_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b638cbc7-fd7e-4660-ae4f-4b726ddd7671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by using cross-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56446614-1b16-4b5e-9e0f-deb336f7307f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cross_encoder_model = Model(tokenizer_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_name=\"sentence-transformers/all-MiniLM-L6-v2\", objective=\"classification\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cross_encoder_model = cross_encoder_model.to(device)\n",
    "\n",
    "weights_path = \"./outputs/checkpoint-10794/pytorch_model.bin\"\n",
    "\n",
    "state_dict = torch.load(weights_path)\n",
    "new_state_dict = {}\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith(\"model.\"):\n",
    "        new_k = k[6:]\n",
    "        new_state_dict[new_k] = v\n",
    "\n",
    "cross_encoder_model.model.load_state_dict(new_state_dict)\n",
    "\n",
    "cross_encoder_model.fc.load_state_dict({\n",
    "    \"weight\": state_dict[\"fc.weight\"],\n",
    "    \"bias\": state_dict[\"fc.bias\"]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c54c9480-5f67-402e-b106-d66869744fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import init_tokenizer\n",
    "\n",
    "class CrossEncoderDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer_name='sentence-transformers/all-MiniLM-L6-v2', max_len=128):\n",
    "        self.df = df\n",
    "        self.topic_texts = []\n",
    "        self.content_texts = []\n",
    "        for i, row in tqdm(df.iterrows()):\n",
    "            if row[\"content_ids\"]:\n",
    "                for content_id in row[\"content_ids\"].split(\" \"):\n",
    "                    self.topic_texts.append(topic_dict[row[\"topic_id\"]])\n",
    "                    self.content_texts.append(content_dict[content_id])\n",
    "                    \n",
    "        self.tokenizer = init_tokenizer(tokenizer_name)\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.topic_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        topic_text = self.topic_texts[idx]\n",
    "        content_text = self.content_texts[idx]\n",
    "        \n",
    "        # topic\n",
    "        topic_inputs = self.tokenizer.encode_plus(\n",
    "            topic_text, \n",
    "            return_tensors = None, \n",
    "            add_special_tokens = True, \n",
    "            max_length = self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation = True\n",
    "        )\n",
    "        for k, v in topic_inputs.items():\n",
    "            topic_inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "            \n",
    "        # content\n",
    "        content_inputs = self.tokenizer.encode_plus(\n",
    "            content_text, \n",
    "            return_tensors = None, \n",
    "            add_special_tokens = True, \n",
    "            max_length = self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation = True\n",
    "        )\n",
    "        for k, v in content_inputs.items():\n",
    "            content_inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "            \n",
    "        return topic_inputs, content_inputs, 0\n",
    "\n",
    "\n",
    "def cross_encoder_collate_fn(batch):\n",
    "    batch = default_collate(batch)\n",
    "    \n",
    "    topic_inputs, content_inputs, labels = batch\n",
    "    mask_len = int(topic_inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in topic_inputs.items():\n",
    "        topic_inputs[k] = topic_inputs[k][:,:mask_len]\n",
    "        \n",
    "    mask_len = int(content_inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in content_inputs.items():\n",
    "        content_inputs[k] = content_inputs[k][:,:mask_len]\n",
    "\n",
    "    return {\n",
    "        \"topic_inputs\": batch[0],\n",
    "        \"content_inputs\": batch[1],\n",
    "        \"labels\": batch[2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dc30573-6a23-46f0-9669-c3ad16fafb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6152it [00:07, 864.81it/s]\n"
     ]
    }
   ],
   "source": [
    "ceds = CrossEncoderDataset(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60fcd4b3-ab98-4c03-9e27-5bd583bf2e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_dataloader = DataLoader(ceds, batch_size=128, shuffle=False, collate_fn=cross_encoder_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc0fd040-d624-4054-abf0-99253908e929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24032/24032 [32:04<00:00, 12.49it/s]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "\n",
    "for inputs in tqdm(ce_dataloader):\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k].to(device)\n",
    "    out = cross_encoder_model(**inputs)\n",
    "    out = torch.sigmoid(out)\n",
    "    res.extend(out.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c0ad058-4a82-4cef-b9fb-abc66b84651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6152it [00:06, 924.35it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_topics = []\n",
    "pred_contents = []\n",
    "\n",
    "for i, row in tqdm(preds.iterrows()):\n",
    "    if row[\"content_ids\"]:\n",
    "        for content_id in row[\"content_ids\"].split(\" \"):\n",
    "            pred_topics.append(row[\"topic_id\"])\n",
    "            pred_contents.append(content_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d6a4fd5-7f63-43ce-91cd-a1af2a12a23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_155829704f08</td>\n",
       "      <td>0.125887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_9a9b9935a1bf</td>\n",
       "      <td>0.129204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_9c1c9c40b02f</td>\n",
       "      <td>0.670831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_0c8abe59a6e9</td>\n",
       "      <td>0.261264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_cb1c57542d1a</td>\n",
       "      <td>0.300368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075995</th>\n",
       "      <td>t_fffe14f1be1e</td>\n",
       "      <td>c_5d511f4b68a4</td>\n",
       "      <td>0.378241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075996</th>\n",
       "      <td>t_fffe14f1be1e</td>\n",
       "      <td>c_276e8d878eaf</td>\n",
       "      <td>0.836427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075997</th>\n",
       "      <td>t_fffe14f1be1e</td>\n",
       "      <td>c_21a702532c7f</td>\n",
       "      <td>0.869691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075998</th>\n",
       "      <td>t_fffe14f1be1e</td>\n",
       "      <td>c_bc1ba339fe0d</td>\n",
       "      <td>0.944993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075999</th>\n",
       "      <td>t_fffe14f1be1e</td>\n",
       "      <td>c_d293854efe3f</td>\n",
       "      <td>0.842973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3076000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               topic_id      content_id     score\n",
       "0        t_00004da3a1b2  c_155829704f08  0.125887\n",
       "1        t_00004da3a1b2  c_9a9b9935a1bf  0.129204\n",
       "2        t_00004da3a1b2  c_9c1c9c40b02f  0.670831\n",
       "3        t_00004da3a1b2  c_0c8abe59a6e9  0.261264\n",
       "4        t_00004da3a1b2  c_cb1c57542d1a  0.300368\n",
       "...                 ...             ...       ...\n",
       "3075995  t_fffe14f1be1e  c_5d511f4b68a4  0.378241\n",
       "3075996  t_fffe14f1be1e  c_276e8d878eaf  0.836427\n",
       "3075997  t_fffe14f1be1e  c_21a702532c7f  0.869691\n",
       "3075998  t_fffe14f1be1e  c_bc1ba339fe0d  0.944993\n",
       "3075999  t_fffe14f1be1e  c_d293854efe3f  0.842973\n",
       "\n",
       "[3076000 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for topic_id, content_id, score in zip(pred_topics, pred_contents, res):\n",
    "new_pred_df = pd.DataFrame({\n",
    "    \"topic_id\": pred_topics,\n",
    "    \"content_id\": pred_contents,\n",
    "    \"score\": [r[0] for r in res]\n",
    "})\n",
    "\n",
    "new_pred_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a6a2bfb5-1f6d-4dc0-9ce5-99a253ffadc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_00004da3a1b2</th>\n",
       "      <td>c_155829704f08 c_9a9b9935a1bf c_9c1c9c40b02f c...</td>\n",
       "      <td>0.12588666379451752 0.12920422852039337 0.6708...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_00069b63a70a</th>\n",
       "      <td>c_ec99a6692b9e c_fda21411f22d c_05ff8bd1fd30 c...</td>\n",
       "      <td>0.8984891176223755 0.8957614302635193 0.986057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_0010852b7049</th>\n",
       "      <td>c_88b82381e693 c_141dbd993fb4 c_4b5bad2b3605 c...</td>\n",
       "      <td>0.3990142345428467 0.7117382287979126 0.788881...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_0016d30772f3</th>\n",
       "      <td>c_c25053d6fafd c_242ddc729eec c_61b851222e17 c...</td>\n",
       "      <td>0.34429931640625 0.5535929799079895 0.21919767...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_001a1575f24a</th>\n",
       "      <td>c_433f60c8c551 c_347dd8aa0601 c_ecb7d1ceb3b4 c...</td>\n",
       "      <td>0.08910951018333435 0.0768064334988594 0.74370...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_ffae9147a5ae</th>\n",
       "      <td>c_8d80e8412b30 c_0331e74bc24c c_6373dae8dbcd c...</td>\n",
       "      <td>0.6131402850151062 0.13943415880203247 0.48580...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_ffd71e80caab</th>\n",
       "      <td>c_b7b01b351f9e c_5775054b5d7c c_c8b39ecdf323 c...</td>\n",
       "      <td>0.0737805888056755 0.07489234954118729 0.23851...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_ffd908252a7d</th>\n",
       "      <td>c_066334236a6d c_d3bf713e9584 c_f15c664feadb c...</td>\n",
       "      <td>0.26526185870170593 0.20486509799957275 0.0548...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_ffe86c1ec81b</th>\n",
       "      <td>c_14c467eb38c6 c_2d1c46350b1b c_ac101b91054f c...</td>\n",
       "      <td>0.28509846329689026 0.5646362900733948 0.79563...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_fffe14f1be1e</th>\n",
       "      <td>c_44cb526a2a44 c_2621c66b9019 c_2bf9d31c585a c...</td>\n",
       "      <td>0.8301949501037598 0.6643848419189453 0.664384...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       content_id  \\\n",
       "topic_id                                                            \n",
       "t_00004da3a1b2  c_155829704f08 c_9a9b9935a1bf c_9c1c9c40b02f c...   \n",
       "t_00069b63a70a  c_ec99a6692b9e c_fda21411f22d c_05ff8bd1fd30 c...   \n",
       "t_0010852b7049  c_88b82381e693 c_141dbd993fb4 c_4b5bad2b3605 c...   \n",
       "t_0016d30772f3  c_c25053d6fafd c_242ddc729eec c_61b851222e17 c...   \n",
       "t_001a1575f24a  c_433f60c8c551 c_347dd8aa0601 c_ecb7d1ceb3b4 c...   \n",
       "...                                                           ...   \n",
       "t_ffae9147a5ae  c_8d80e8412b30 c_0331e74bc24c c_6373dae8dbcd c...   \n",
       "t_ffd71e80caab  c_b7b01b351f9e c_5775054b5d7c c_c8b39ecdf323 c...   \n",
       "t_ffd908252a7d  c_066334236a6d c_d3bf713e9584 c_f15c664feadb c...   \n",
       "t_ffe86c1ec81b  c_14c467eb38c6 c_2d1c46350b1b c_ac101b91054f c...   \n",
       "t_fffe14f1be1e  c_44cb526a2a44 c_2621c66b9019 c_2bf9d31c585a c...   \n",
       "\n",
       "                                                            score  \n",
       "topic_id                                                           \n",
       "t_00004da3a1b2  0.12588666379451752 0.12920422852039337 0.6708...  \n",
       "t_00069b63a70a  0.8984891176223755 0.8957614302635193 0.986057...  \n",
       "t_0010852b7049  0.3990142345428467 0.7117382287979126 0.788881...  \n",
       "t_0016d30772f3  0.34429931640625 0.5535929799079895 0.21919767...  \n",
       "t_001a1575f24a  0.08910951018333435 0.0768064334988594 0.74370...  \n",
       "...                                                           ...  \n",
       "t_ffae9147a5ae  0.6131402850151062 0.13943415880203247 0.48580...  \n",
       "t_ffd71e80caab  0.0737805888056755 0.07489234954118729 0.23851...  \n",
       "t_ffd908252a7d  0.26526185870170593 0.20486509799957275 0.0548...  \n",
       "t_ffe86c1ec81b  0.28509846329689026 0.5646362900733948 0.79563...  \n",
       "t_fffe14f1be1e  0.8301949501037598 0.6643848419189453 0.664384...  \n",
       "\n",
       "[6152 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first get top-k, then filter by confidence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bb575e1c-ea33-4edc-aed0-1a1c0c78f171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6152it [00:01, 4159.96it/s]\n"
     ]
    }
   ],
   "source": [
    "top_k = 5\n",
    "\n",
    "\n",
    "final_topics = []\n",
    "final_contents = []\n",
    "final_scores = []\n",
    "\n",
    "for i, row in tqdm(new_pred_df.groupby('topic_id').agg({'content_id': \" \".join, \"score\": lambda x: \" \".join([str(e) for e in x])}).iterrows()):\n",
    "    topic_id = i # row[\"topic_id\"]\n",
    "    content_ids = row[\"content_id\"].split(\" \")\n",
    "    scores = [float(s) for s in row[\"score\"].split(\" \")]\n",
    "    \n",
    "    data = list(zip(content_ids, scores))\n",
    "    data.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    data = data[:top_k]\n",
    "    content_ids = \" \".join([e[0] for e in data])\n",
    "    scores = \" \".join([e[0] for e in data])\n",
    "    \n",
    "    final_topics.append(i)\n",
    "    final_contents.append(content_ids)\n",
    "    final_scores.append(scores)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7801de35-16a0-45e2-af8e-26e3646e45ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c_bca2888db852', 0.9983574748039246),\n",
       " ('c_73b95605efec', 0.9976263642311096),\n",
       " ('c_3d11280c1fd5', 0.9967357516288757),\n",
       " ('c_d61dd657895b', 0.9956411123275757),\n",
       " ('c_2db7d7219e04', 0.9953600764274597)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d82d0d97-862a-4be8-8e67-bf3c9718a16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_18039de420ee c_2b39c42ce5c6 c_8bbadb894798 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00069b63a70a</td>\n",
       "      <td>c_fbb55ec5bb93 c_500976c1d732 c_709a113276da c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_0010852b7049</td>\n",
       "      <td>c_38ba59722f55 c_e0f240fac0f9 c_a29b03b77295 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_0016d30772f3</td>\n",
       "      <td>c_9f39934ac915 c_3becaf30edf5 c_e22c3df3477d c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_001a1575f24a</td>\n",
       "      <td>c_94bc9ad9a437 c_df0e4b6bff98 c_8f2b7b7986e6 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>t_ffae9147a5ae</td>\n",
       "      <td>c_51bda103b308 c_6ca2a3bd3887 c_54b9e3f2a634 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>t_ffd71e80caab</td>\n",
       "      <td>c_101554ac7f0a c_f72aca5be36d c_4c8238d9cfd0 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>t_ffd908252a7d</td>\n",
       "      <td>c_46e9acc70642 c_156ec8d75c37 c_148635f123ee c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6150</th>\n",
       "      <td>t_ffe86c1ec81b</td>\n",
       "      <td>c_ba717080dd61 c_18039de420ee c_f78a4f87982f c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>t_fffe14f1be1e</td>\n",
       "      <td>c_bca2888db852 c_73b95605efec c_3d11280c1fd5 c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            topic_id                                        content_ids\n",
       "0     t_00004da3a1b2  c_18039de420ee c_2b39c42ce5c6 c_8bbadb894798 c...\n",
       "1     t_00069b63a70a  c_fbb55ec5bb93 c_500976c1d732 c_709a113276da c...\n",
       "2     t_0010852b7049  c_38ba59722f55 c_e0f240fac0f9 c_a29b03b77295 c...\n",
       "3     t_0016d30772f3  c_9f39934ac915 c_3becaf30edf5 c_e22c3df3477d c...\n",
       "4     t_001a1575f24a  c_94bc9ad9a437 c_df0e4b6bff98 c_8f2b7b7986e6 c...\n",
       "...              ...                                                ...\n",
       "6147  t_ffae9147a5ae  c_51bda103b308 c_6ca2a3bd3887 c_54b9e3f2a634 c...\n",
       "6148  t_ffd71e80caab  c_101554ac7f0a c_f72aca5be36d c_4c8238d9cfd0 c...\n",
       "6149  t_ffd908252a7d  c_46e9acc70642 c_156ec8d75c37 c_148635f123ee c...\n",
       "6150  t_ffe86c1ec81b  c_ba717080dd61 c_18039de420ee c_f78a4f87982f c...\n",
       "6151  t_fffe14f1be1e  c_bca2888db852 c_73b95605efec c_3d11280c1fd5 c...\n",
       "\n",
       "[6152 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds = pd.DataFrame({\n",
    "    \"topic_id\": final_topics,\n",
    "    \"content_ids\": final_contents\n",
    "})\n",
    "final_preds = final_preds.sort_values(\"topic_id\")    \n",
    "\n",
    "final_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9bc54531-309d-4856-ab20-1f17eb0f0f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00069b63a70a</td>\n",
       "      <td>c_11a1dc0bfb99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t_0010852b7049</td>\n",
       "      <td>c_0baf72ed7e1e c_5eca28e2cdb4 c_6a5472fb1483 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>t_0016d30772f3</td>\n",
       "      <td>c_061d9f90bb06 c_242ddc729eec c_61b851222e17 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>t_001a1575f24a</td>\n",
       "      <td>c_433f60c8c551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61448</th>\n",
       "      <td>t_ffae9147a5ae</td>\n",
       "      <td>c_542c5451ddc6 c_691dd2887cbb c_861473e6d8ac c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61483</th>\n",
       "      <td>t_ffd71e80caab</td>\n",
       "      <td>c_5775054b5d7c c_789d19c527c8 c_b7b01b351f9e c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61484</th>\n",
       "      <td>t_ffd908252a7d</td>\n",
       "      <td>c_5d014c6f7def c_d84eedcb7d52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61497</th>\n",
       "      <td>t_ffe86c1ec81b</td>\n",
       "      <td>c_01a66ded6b8e c_852725771d84 c_8a7cc1fb5a5f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61515</th>\n",
       "      <td>t_fffe14f1be1e</td>\n",
       "      <td>c_cece166bad6a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             topic_id                                        content_ids\n",
       "0      t_00004da3a1b2  c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...\n",
       "2      t_00069b63a70a                                     c_11a1dc0bfb99\n",
       "9      t_0010852b7049  c_0baf72ed7e1e c_5eca28e2cdb4 c_6a5472fb1483 c...\n",
       "14     t_0016d30772f3  c_061d9f90bb06 c_242ddc729eec c_61b851222e17 c...\n",
       "16     t_001a1575f24a                                     c_433f60c8c551\n",
       "...               ...                                                ...\n",
       "61448  t_ffae9147a5ae  c_542c5451ddc6 c_691dd2887cbb c_861473e6d8ac c...\n",
       "61483  t_ffd71e80caab  c_5775054b5d7c c_789d19c527c8 c_b7b01b351f9e c...\n",
       "61484  t_ffd908252a7d                      c_5d014c6f7def c_d84eedcb7d52\n",
       "61497  t_ffe86c1ec81b       c_01a66ded6b8e c_852725771d84 c_8a7cc1fb5a5f\n",
       "61515  t_fffe14f1be1e                                     c_cece166bad6a\n",
       "\n",
       "[6152 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "63fa7791-6edf-46f2-ae6d-3f741cc2b591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = corrs_df[corrs_df.topic_id.isin(val_topic_ids)].sort_values(\"topic_id\")    \n",
    "f2_score(gt[\"content_ids\"], final_preds[\"content_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "687ef3e9-9f22-4bfa-9f15-af81684bdd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27412"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum([len(v.split(\" \")) for v in gt.content_ids.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e3e8ed-033a-4a68-b2a3-9420edd159dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "efd63ffc-2c80-4fc1-9312-4d4e59cdfd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0219"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "904cb7d7-1815-4127-b026-0fae69327778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_ids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_001edc523bd1</th>\n",
       "      <td>c_ebcb03bff955 c_a39a8828edde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_003cf02b4682</th>\n",
       "      <td>c_93f53e33ff13 c_8f76ce76c4a4 c_0fdfaf22bc61 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_00459f9ca137</th>\n",
       "      <td>c_c969c29a276d c_ab2494ea3a05 c_fd88d24c2a2b c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_006c08bbf736</th>\n",
       "      <td>c_bcc675a02e9d c_ebcb03bff955 c_a39a8828edde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_00d6699a0cf3</th>\n",
       "      <td>c_b79522727dd3 c_47c14ba67fb4 c_fbb55ec5bb93 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_feb52d29fab9</th>\n",
       "      <td>c_dae3c5a22d9f c_326273c51a91 c_b667cc507d1d c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_fec1c6435fa1</th>\n",
       "      <td>c_06621ea55b08 c_1eb18256601d c_616e11cce0de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_fed368bb2adb</th>\n",
       "      <td>c_b4094fd88e15 c_07f6b3818fb1 c_3ea6fa70275d c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_fef7b464b6da</th>\n",
       "      <td>c_bcc675a02e9d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_ff03f2b15197</th>\n",
       "      <td>c_952c4ac3838b c_5fc9e722b9e1 c_7556d0cf64c0 c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>927 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      content_ids\n",
       "topic_id                                                         \n",
       "t_001edc523bd1                      c_ebcb03bff955 c_a39a8828edde\n",
       "t_003cf02b4682  c_93f53e33ff13 c_8f76ce76c4a4 c_0fdfaf22bc61 c...\n",
       "t_00459f9ca137  c_c969c29a276d c_ab2494ea3a05 c_fd88d24c2a2b c...\n",
       "t_006c08bbf736       c_bcc675a02e9d c_ebcb03bff955 c_a39a8828edde\n",
       "t_00d6699a0cf3  c_b79522727dd3 c_47c14ba67fb4 c_fbb55ec5bb93 c...\n",
       "...                                                           ...\n",
       "t_feb52d29fab9  c_dae3c5a22d9f c_326273c51a91 c_b667cc507d1d c...\n",
       "t_fec1c6435fa1       c_06621ea55b08 c_1eb18256601d c_616e11cce0de\n",
       "t_fed368bb2adb  c_b4094fd88e15 c_07f6b3818fb1 c_3ea6fa70275d c...\n",
       "t_fef7b464b6da                                     c_bcc675a02e9d\n",
       "t_ff03f2b15197  c_952c4ac3838b c_5fc9e722b9e1 c_7556d0cf64c0 c...\n",
       "\n",
       "[927 rows x 1 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4e88ec2a-2432-49bc-b6b5-e6da61ca7e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00069b63a70a</td>\n",
       "      <td>c_11a1dc0bfb99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t_0010852b7049</td>\n",
       "      <td>c_0baf72ed7e1e c_5eca28e2cdb4 c_6a5472fb1483 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>t_0016d30772f3</td>\n",
       "      <td>c_061d9f90bb06 c_242ddc729eec c_61b851222e17 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>t_001a1575f24a</td>\n",
       "      <td>c_433f60c8c551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61448</th>\n",
       "      <td>t_ffae9147a5ae</td>\n",
       "      <td>c_542c5451ddc6 c_691dd2887cbb c_861473e6d8ac c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61483</th>\n",
       "      <td>t_ffd71e80caab</td>\n",
       "      <td>c_5775054b5d7c c_789d19c527c8 c_b7b01b351f9e c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61484</th>\n",
       "      <td>t_ffd908252a7d</td>\n",
       "      <td>c_5d014c6f7def c_d84eedcb7d52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61497</th>\n",
       "      <td>t_ffe86c1ec81b</td>\n",
       "      <td>c_01a66ded6b8e c_852725771d84 c_8a7cc1fb5a5f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61515</th>\n",
       "      <td>t_fffe14f1be1e</td>\n",
       "      <td>c_cece166bad6a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             topic_id                                        content_ids\n",
       "0      t_00004da3a1b2  c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...\n",
       "2      t_00069b63a70a                                     c_11a1dc0bfb99\n",
       "9      t_0010852b7049  c_0baf72ed7e1e c_5eca28e2cdb4 c_6a5472fb1483 c...\n",
       "14     t_0016d30772f3  c_061d9f90bb06 c_242ddc729eec c_61b851222e17 c...\n",
       "16     t_001a1575f24a                                     c_433f60c8c551\n",
       "...               ...                                                ...\n",
       "61448  t_ffae9147a5ae  c_542c5451ddc6 c_691dd2887cbb c_861473e6d8ac c...\n",
       "61483  t_ffd71e80caab  c_5775054b5d7c c_789d19c527c8 c_b7b01b351f9e c...\n",
       "61484  t_ffd908252a7d                      c_5d014c6f7def c_d84eedcb7d52\n",
       "61497  t_ffe86c1ec81b       c_01a66ded6b8e c_852725771d84 c_8a7cc1fb5a5f\n",
       "61515  t_fffe14f1be1e                                     c_cece166bad6a\n",
       "\n",
       "[6152 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aced63-12de-4b7f-84ea-8a82bfceb0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810cd49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fb070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gt sims\n",
    "# list_all_content_ids = list(all_content_ids)\n",
    "\n",
    "# all_sims = []\n",
    "# for i, row in tqdm(gt.iterrows()):\n",
    "#     sims = []\n",
    "\n",
    "#     t_e = topic_embs[all_test_ids.index(row[\"topic_id\"])]\n",
    "#     for content_id in row[\"content_ids\"].split(\" \"):\n",
    "#         c_e = content_embs[list_all_content_ids.index(content_id)]\n",
    "#         sims.append(cosine_similarity(torch.from_numpy(t_e), torch.from_numpy(c_e), 0))\n",
    "    \n",
    "#     all_sims.append(\" \".join([str(s.item())[:5] for s in sims]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e502243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1228aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prediction sims\n",
    "\n",
    "# list_all_content_ids = list(all_content_ids)\n",
    "\n",
    "# all_preds_sims = []\n",
    "# for i, row in tqdm(preds.iterrows()):\n",
    "#     sims = []\n",
    "\n",
    "#     t_e = topic_embs[all_test_ids.index(row[\"topic_id\"])]\n",
    "#     if not row[\"content_ids\"]:\n",
    "#         continue\n",
    "#     for content_id in row[\"content_ids\"].split(\" \"):\n",
    "#         c_e = content_embs[list_all_content_ids.index(content_id)]\n",
    "#         sims.append(cosine_similarity(torch.from_numpy(t_e), torch.from_numpy(c_e), 0))\n",
    "    \n",
    "#     all_preds_sims.append(\" \".join([str(s.item())[:5] for s in sims]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b988d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_preds_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e9b54f-c4d3-48be-bb7f-80eaa30e3c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# sample_preds = pd.DataFrame({\n",
    "#     \"content_ids\": [\n",
    "#         \"a b c\"\n",
    "#     ]\n",
    "# })\n",
    "\n",
    "# sample_gts = pd.DataFrame({\n",
    "#     \"content_ids\": [\n",
    "#         \"a d e f g h\"\n",
    "#     ]\n",
    "# })\n",
    "# f2_score(\n",
    "#     sample_gts[\"content_ids\"],\n",
    "#     sample_preds[\"content_ids\"],\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
