{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa54d8-22bc-4134-9fff-bf6c8120ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install annoy\n",
    "# import os\n",
    "# # print(os.environ[\"LD_LIBRARY_PATH\"])\n",
    "# os.environ[\"LD_LIBRARY_PATH\"] = \"/opt/conda/lib/python3.8/site-packages/torch/lib:/usr/local/cuda-11.3/lib64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbebda6-bd0f-418f-92f4-a2839c8155b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text\n",
    "# from textblob import TextBlob\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "def decontracted(phrase):\n",
    "\n",
    "    # Specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    # ..\n",
    "\n",
    "    # General\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    # ..\n",
    "\n",
    "    return phrase\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in list(string.punctuation): text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "def clean_number(text):\n",
    "    text = re.sub(r'(\\d+)([a-zA-Z])', '\\g<1> \\g<2>', text)\n",
    "    text = re.sub(r'(\\d+) (th|st|nd|rd) ', '\\g<1>\\g<2> ', text)\n",
    "    text = re.sub(r'(\\d+),(\\d+)', '\\g<1>\\g<2>', text)\n",
    "    return text\n",
    "\n",
    "def clean_whitespace(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def clean_repeat_words(text):\n",
    "    return re.sub(r\"(\\w*)(\\w)\\2(\\w*)\", r\"\\1\\2\\3\", text)\n",
    "\n",
    "def clean_text(text):\n",
    "    # text_blob = TextBlob(text)\n",
    "    # text = str(text_blob.correct())\n",
    "    text = str(text)\n",
    "    text = decontracted(text)\n",
    "    text = remove_punctuations(text)\n",
    "    text = clean_number(text)\n",
    "    text = clean_whitespace(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96a1dd2-a3b5-40ec-87e6-4231794a3bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from dataset import AutoTokenizer, LANGUAGE_TOKENS, CATEGORY_TOKENS, LEVEL_TOKENS, KIND_TOKENS, OTHER_TOKENS\n",
    "from model import Model\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, default_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45499b1d-2636-4ffd-9d4f-e578ce45e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "TEST_MODE = False\n",
    "\n",
    "# --------------------- VALIDATION SET --------------------------\n",
    "from tqdm import tqdm\n",
    "if not TEST_MODE:\n",
    "    data_df = pd.read_csv(\"./data/supervised_correlations.csv\")\n",
    "    fold = 0\n",
    "val_topic_ids = list(data_df[data_df[\"fold\"] == fold].topics_ids)\n",
    "del data_df\n",
    "\n",
    "data_folder = Path(\"./data\")\n",
    "# TODO: we have to process for test set ourselves\n",
    "contents_df = pd.read_csv(data_folder/'content.csv')\n",
    "contents_df = contents_df.fillna('')\n",
    "contents_df['title_len'] = contents_df.title.str.len()\n",
    "contents_df = contents_df.sort_values(by='title_len', axis=0).reset_index(drop=True).drop(columns=['title_len'])\n",
    "topics_df = pd.read_csv(data_folder/'topics.csv')\n",
    "topics_df = topics_df.fillna('')\n",
    "topics_df['title_len'] = topics_df.title.str.len()\n",
    "topics_df = topics_df.sort_values(by='title_len', axis=0).reset_index(drop=True).drop(columns=['title_len'])\n",
    "subs_df = pd.read_csv(data_folder/'sample_submission.csv')\n",
    "corrs_df = pd.read_csv(data_folder/'correlations.csv')\n",
    "\n",
    "\n",
    "topics_df[\"title\"] = topics_df[\"title\"].apply(clean_text)\n",
    "topics_df[\"description\"] = topics_df[\"description\"].apply(clean_text)\n",
    "\n",
    "contents_df[\"title\"] = contents_df[\"title\"].apply(clean_text)\n",
    "contents_df[\"description\"] = contents_df[\"description\"].apply(clean_text)\n",
    "# contents_df[\"text\"] = contents_df[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised_correlations = pd.read_csv(\"data/supervised_correlations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised_correlations[(supervised_correlations[\"topics_ids\"].isin(val_topic_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised_correlations[(supervised_correlations[\"topics_ids\"].isin(val_topic_ids)) & (supervised_correlations[\"target\"] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82366c3e-915e-4dc6-9926-305514f27a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "if TEST_MODE:\n",
    "    topics_df = topics_df[topics_df.id.isin(subs_df.topic_id)]\n",
    "else: # VAL_MODE\n",
    "    topics_df = topics_df[topics_df.id.isin(val_topic_ids)]\n",
    "\n",
    "topic_dict = {}\n",
    "for i, (index, row) in tqdm(enumerate(topics_df.iterrows())):\n",
    "    text = \"<|topic|>\" + f\"<|lang_{row['language']}|>\" + f\"<|category_{row['category']}|>\" + f\"<|level_{row['level']}|>\"\n",
    "    text += \"<s_title>\" + row[\"title\"] + \"</s_title>\" + \"<s_description>\" + row[\"description\"] + \"</s_description>\"\n",
    "    topic_dict[row[\"id\"]] = text\n",
    "\n",
    "content_dict = {}\n",
    "for i, (index, row) in tqdm(enumerate(contents_df.iterrows())):\n",
    "    text = \"<|content|>\" + f\"<|lang_{row['language']}|>\" + f\"<|kind_{row['kind']}|>\"\n",
    "    text += \"<s_title>\" + row[\"title\"] + \"</s_title>\" + \"<s_description>\" + row[\"description\"] + \"</s_description>\" # + \"<s_text>\" + row[\"text\"] + \"</s_text>\"\n",
    "    content_dict[row[\"id\"]] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2782f1a-36d1-4b5a-89b6-926aeed6541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df[\"topic_text\"] = topic_dict.values()\n",
    "topics_df[\"topic_text\"] = topics_df[\"topic_text\"] # .apply(lambda x: x[:2048])\n",
    "\n",
    "contents_df[\"content_text\"] = content_dict.values()\n",
    "contents_df[\"content_text\"] = contents_df[\"content_text\"] # .apply(lambda x: x[:2048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd58ee0-c996-4b14-9c3b-7d22847dc8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer_name='xlm-roberta-base', max_len=512):\n",
    "        self.texts = texts\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.tokenizer.add_special_tokens(dict(additional_special_tokens=LANGUAGE_TOKENS + CATEGORY_TOKENS + LEVEL_TOKENS + KIND_TOKENS + OTHER_TOKENS))\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        \n",
    "        # topic\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, \n",
    "            return_tensors = None, \n",
    "            add_special_tokens = True, \n",
    "            max_length = self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation = True\n",
    "        )\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "            \n",
    "        return inputs\n",
    "    \n",
    "def collate_fn(inputs):\n",
    "    inputs = default_collate(inputs)\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "        \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09637446-9ae8-4a8b-b60e-629097b0d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dataset = InferenceDataset(texts=list(topics_df.topic_text.values), tokenizer_name='sentence-transformers/all-MiniLM-L6-v2', max_len=128)\n",
    "topic_dataloader = DataLoader(topic_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d32b1-318b-4424-af01-bbf075298558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Model(tokenizer_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_name=\"sentence-transformers/all-MiniLM-L6-v2\", objective=\"both\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "weights_path = \"/home/jovyan/lecr/outputs_siamese/checkpoint-81549/pytorch_model.bin\"\n",
    "\n",
    "state_dict = torch.load(weights_path)\n",
    "new_state_dict = {}\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith(\"model.\"):\n",
    "        new_k = k[6:]\n",
    "        new_state_dict[new_k] = v\n",
    "\n",
    "model.model.load_state_dict(new_state_dict)\n",
    "\n",
    "if \"fc.weight\" in state_dict:\n",
    "    model.fc.load_state_dict({\n",
    "        \"weight\": state_dict[\"fc.weight\"],\n",
    "        \"bias\": state_dict[\"fc.bias\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f33aac-6b81-4c11-9855-4e627d36b2ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "topic_embs = []\n",
    "\n",
    "for inputs in tqdm(topic_dataloader):\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k].to(device)\n",
    "    out = model.feature(inputs)\n",
    "    topic_embs.extend(out.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f63849-09ae-43c5-bb5b-1bdbcba33f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_dataset = InferenceDataset(texts=list(contents_df.content_text.values), tokenizer_name='sentence-transformers/all-MiniLM-L6-v2', max_len=128)\n",
    "content_dataloader = DataLoader(content_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# # \n",
    "# del contents_df[\"text\"]\n",
    "# del contents_df\n",
    "\n",
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    "content_embs = []\n",
    "\n",
    "for inputs in tqdm(content_dataloader):\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k].to(device)\n",
    "    out = model.feature(inputs)\n",
    "    content_embs.extend(out.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a621519-5667-4375-bfaf-4212315d6330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from saved files\n",
    "torch.save(topic_embs, \"./data/topic_embs.pt\")\n",
    "torch.save(content_embs, \"./data/content_embs.pt\")\n",
    "\n",
    "# topic_embs = torch.load(\"./data/topic_embs.pt\")\n",
    "# content_embs = torch.load(\"./data/content_embs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fuzzywuzzy annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_content_embs = []\n",
    "# for emb in tqdm(content_embs):\n",
    "#     normalized_content_embs.append(F.normalize(torch.from_numpy(emb), p=2, dim=0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823d481-81c7-4038-be02-4cced8eee0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "\n",
    "content_forest = AnnoyIndex(content_embs[0].shape[0], metric='angular')\n",
    "for i, item in tqdm(enumerate(content_embs), total=len(content_embs)):\n",
    "    content_forest.add_item(i, item)\n",
    "content_forest.build(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda876a8-cfb2-4697-88d7-e313f3a1669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics = topics_df[topics_df.has_content==True][['id', 'title', 'language']].reset_index(drop=True)\n",
    "\n",
    "topics = topics_df\n",
    "\n",
    "test = topics\n",
    "all_content_ids = contents_df.id.to_numpy()\n",
    "all_content_titles = contents_df.title.to_numpy()\n",
    "all_content_language = contents_df.language.to_numpy()\n",
    "all_test_ids = list(topics.id)\n",
    "all_test_title = list(topics.title)\n",
    "all_test_language = list(test.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a11b16-c327-4ce4-9b38-f3e3bec2d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_forest.get_nns_by_vector(topic_embs[5], 10, include_distances=True)"
   ]
  },
  {
   "source": [
    "indexes_dict = {}\n",
    "fuzzy_dict = {}\n",
    "classification_dict = {}"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4596424-e963-48fd-8f4a-627e77f82c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find by distance instead\n",
    "\n",
    "nearest_content_count = 500\n",
    "fuzzy_filter = 80\n",
    "THRESHOLD = 0\n",
    "# for fuzzy_filter in range(5, 50, 5):\n",
    "#     for t in range(1, 10, 2):\n",
    "#         THRESHOLD = t / 100\n",
    "preds = []\n",
    "for i, t_e in tqdm(enumerate(topic_embs), total=len(topic_embs), desc=f'Getting Preds'):\n",
    "    if i in indexes_dict:\n",
    "        indexes, distances = indexes_dict[i]\n",
    "    else:\n",
    "        indexes, distances = content_forest.get_nns_by_vector(\n",
    "            # F.normalize(torch.from_numpy(t_e), p=2, dim=0),\n",
    "            t_e,\n",
    "            nearest_content_count,\n",
    "            include_distances=True\n",
    "        )\n",
    "        # indexes = [i for i, d in zip(indexes, distances) if d < 10]\n",
    "        indexes_dict[i] = indexes, distances\n",
    "\n",
    "    topic_id = all_test_ids[i]\n",
    "    topic_text = all_test_title[i]\n",
    "    topic_lang = all_test_language[i]\n",
    "\n",
    "    # for idx in indexes:\n",
    "    #     if topic_lang != all_content_language[idx]:\n",
    "    #         indexes.remove(idx)\n",
    "    \n",
    "    # filtered_indexes = []\n",
    "    # for idx in indexes:\n",
    "    #     if topic_lang != all_content_language[idx]:\n",
    "    #         continue\n",
    "    #     if (i, idx) in fuzzy_dict:\n",
    "    #         fuzzy_value = fuzzy_dict[(i, idx)]\n",
    "    #     else:\n",
    "    #         fuzzy_value = fuzz.token_set_ratio(all_content_titles[idx], topic_text)\n",
    "    #         fuzzy_dict[(i, idx)] = fuzzy_value\n",
    "        \n",
    "    #     if fuzzy_value > fuzzy_filter:\n",
    "    #         filtered_indexes.append(idx)\n",
    "        \n",
    "    #     if (i, idx) in classification_dict:\n",
    "    #         score = classification_dict[(i, idx)]\n",
    "    #     else:\n",
    "    #         topic_features = torch.from_numpy(t_e).to(device)\n",
    "    #         content_features = torch.from_numpy(content_embs[idx]).to(device)\n",
    "    #         score = torch.sigmoid(model.fc(torch.cat([topic_features, content_features, topic_features - content_features], -1))).item()\n",
    "    #         classification_dict[(i, idx)] = score\n",
    "    #     if score < THRESHOLD and idx in filtered_indexes:\n",
    "    #         filtered_indexes.remove(idx)\n",
    "    # ind2dis = {ind: d for ind, d in zip(indexes, distances)}\n",
    "    # if len(filtered_indexes) == 0:\n",
    "    #     indexes = filtered_indexes[:8] # list(set(filtered_indexes + indexes[:8-len(filtered_indexes)]))\n",
    "    # else:\n",
    "    #     indexes = filtered_indexes[:8]\n",
    "    content_ids = all_content_ids[indexes]\n",
    "    preds.append({\n",
    "        'topic_id': topic_id,\n",
    "        'content_ids': ' '.join(content_ids),\n",
    "        # 'distances': ' '.join([str(ind2dis[ind]) for ind in indexes]),\n",
    "    })\n",
    "preds = pd.DataFrame.from_records(preds)\n",
    "\n",
    "preds.to_csv('submission.csv', index=False)\n",
    "\n",
    "if not TEST_MODE:\n",
    "    from engine import f2_score\n",
    "    gt = corrs_df[corrs_df.topic_id.isin(val_topic_ids)].sort_values(\"topic_id\")    \n",
    "    preds = preds.sort_values(\"topic_id\")    \n",
    "    print(\"fuzzy_filter\", fuzzy_filter, \"THRESHOLD:\", THRESHOLD, \"f2_score\", f2_score(gt[\"content_ids\"], preds[\"content_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_pos_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    int_true = np.array([len(x[0] & x[1]) / len(x[0]) for x in zip(y_true, y_pred)])\n",
    "    return round(np.mean(int_true), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pos_score(gt[\"content_ids\"], preds[\"content_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gt sims\n",
    "# list_all_content_ids = list(all_content_ids)\n",
    "\n",
    "# all_sims = []\n",
    "# for i, row in tqdm(gt.iterrows()):\n",
    "#     sims = []\n",
    "\n",
    "#     t_e = topic_embs[all_test_ids.index(row[\"topic_id\"])]\n",
    "#     for content_id in row[\"content_ids\"].split(\" \"):\n",
    "#         c_e = content_embs[list_all_content_ids.index(content_id)]\n",
    "#         sims.append(cosine_similarity(torch.from_numpy(t_e), torch.from_numpy(c_e), 0))\n",
    "    \n",
    "#     all_sims.append(\" \".join([str(s.item())[:5] for s in sims]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prediction sims\n",
    "\n",
    "# list_all_content_ids = list(all_content_ids)\n",
    "\n",
    "# all_preds_sims = []\n",
    "# for i, row in tqdm(preds.iterrows()):\n",
    "#     sims = []\n",
    "\n",
    "#     t_e = topic_embs[all_test_ids.index(row[\"topic_id\"])]\n",
    "#     if not row[\"content_ids\"]:\n",
    "#         continue\n",
    "#     for content_id in row[\"content_ids\"].split(\" \"):\n",
    "#         c_e = content_embs[list_all_content_ids.index(content_id)]\n",
    "#         sims.append(cosine_similarity(torch.from_numpy(t_e), torch.from_numpy(c_e), 0))\n",
    "    \n",
    "#     all_preds_sims.append(\" \".join([str(s.item())[:5] for s in sims]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_preds_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e9b54f-c4d3-48be-bb7f-80eaa30e3c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# sample_preds = pd.DataFrame({\n",
    "#     \"content_ids\": [\n",
    "#         \"a b c\"\n",
    "#     ]\n",
    "# })\n",
    "\n",
    "# sample_gts = pd.DataFrame({\n",
    "#     \"content_ids\": [\n",
    "#         \"a d e f g h\"\n",
    "#     ]\n",
    "# })\n",
    "# f2_score(\n",
    "#     sample_gts[\"content_ids\"],\n",
    "#     sample_preds[\"content_ids\"],\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}