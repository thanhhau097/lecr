{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa54d8-22bc-4134-9fff-bf6c8120ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install annoy\n",
    "# import os\n",
    "# # print(os.environ[\"LD_LIBRARY_PATH\"])\n",
    "# os.environ[\"LD_LIBRARY_PATH\"] = \"/opt/conda/lib/python3.8/site-packages/torch/lib:/usr/local/cuda-11.3/lib64\"\n",
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbebda6-bd0f-418f-92f4-a2839c8155b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text\n",
    "# from textblob import TextBlob\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "def decontracted(phrase):\n",
    "\n",
    "    # Specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    # ..\n",
    "\n",
    "    # General\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    # ..\n",
    "\n",
    "    return phrase\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in list(string.punctuation): text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "def clean_number(text):\n",
    "    text = re.sub(r'(\\d+)([a-zA-Z])', '\\g<1> \\g<2>', text)\n",
    "    text = re.sub(r'(\\d+) (th|st|nd|rd) ', '\\g<1>\\g<2> ', text)\n",
    "    text = re.sub(r'(\\d+),(\\d+)', '\\g<1>\\g<2>', text)\n",
    "    return text\n",
    "\n",
    "def clean_whitespace(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def clean_repeat_words(text):\n",
    "    return re.sub(r\"(\\w*)(\\w)\\2(\\w*)\", r\"\\1\\2\\3\", text)\n",
    "\n",
    "def clean_text(text):\n",
    "    # text_blob = TextBlob(text)\n",
    "    # text = str(text_blob.correct())\n",
    "    text = str(text)\n",
    "    text = decontracted(text)\n",
    "    text = remove_punctuations(text)\n",
    "    text = clean_number(text)\n",
    "    text = clean_whitespace(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96a1dd2-a3b5-40ec-87e6-4231794a3bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from dataset import AutoTokenizer, LANGUAGE_TOKENS, CATEGORY_TOKENS, LEVEL_TOKENS, KIND_TOKENS, OTHER_TOKENS\n",
    "from model import Model\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, default_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45499b1d-2636-4ffd-9d4f-e578ce45e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "TEST_MODE = False\n",
    "\n",
    "# --------------------- VALIDATION SET --------------------------\n",
    "from tqdm import tqdm\n",
    "if not TEST_MODE:\n",
    "    data_df = pd.read_csv(\"./data/supervised_correlations.csv\")\n",
    "    fold = 0\n",
    "val_topic_ids = list(data_df[data_df[\"fold\"] == fold].topics_ids)\n",
    "# del data_df\n",
    "\n",
    "data_folder = Path(\"./data\")\n",
    "# TODO: we have to process for test set ourselves\n",
    "contents_df = pd.read_csv(data_folder/'content.csv')\n",
    "contents_df = contents_df.fillna('')\n",
    "contents_df['title_len'] = contents_df.title.str.len()\n",
    "contents_df = contents_df.sort_values(by='title_len', axis=0).reset_index(drop=True).drop(columns=['title_len'])\n",
    "topics_df = pd.read_csv(data_folder/'topics.csv')\n",
    "topics_df = topics_df.fillna('')\n",
    "topics_df['title_len'] = topics_df.title.str.len()\n",
    "topics_df = topics_df.sort_values(by='title_len', axis=0).reset_index(drop=True).drop(columns=['title_len'])\n",
    "subs_df = pd.read_csv(data_folder/'sample_submission.csv')\n",
    "corrs_df = pd.read_csv(data_folder/'correlations.csv')\n",
    "\n",
    "\n",
    "topics_df[\"title\"] = topics_df[\"title\"].apply(clean_text)\n",
    "topics_df[\"description\"] = topics_df[\"description\"].apply(clean_text)\n",
    "\n",
    "contents_df[\"title\"] = contents_df[\"title\"].apply(clean_text)\n",
    "contents_df[\"description\"] = contents_df[\"description\"].apply(clean_text)\n",
    "# contents_df[\"text\"] = contents_df[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised_correlations = pd.read_csv(\"data/supervised_correlations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02882b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised_correlations[(supervised_correlations[\"topics_ids\"].isin(val_topic_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ea076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised_correlations[(supervised_correlations[\"topics_ids\"].isin(val_topic_ids)) & (supervised_correlations[\"target\"] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82366c3e-915e-4dc6-9926-305514f27a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "if TEST_MODE:\n",
    "    topics_df = topics_df[topics_df.id.isin(subs_df.topic_id)]\n",
    "else: # VAL_MODE\n",
    "    topics_df = topics_df[topics_df.id.isin(val_topic_ids)]\n",
    "\n",
    "topic_dict = {}\n",
    "for i, (index, row) in tqdm(enumerate(topics_df.iterrows())):\n",
    "    text = \"<|topic|>\" + f\"<|lang_{row['language']}|>\" + f\"<|category_{row['category']}|>\" + f\"<|level_{row['level']}|>\"\n",
    "    text += \"<s_title>\" + row[\"title\"] + \"</s_title>\" + \"<s_description>\" + row[\"description\"] + \"</s_description>\"\n",
    "    topic_dict[row[\"id\"]] = text\n",
    "\n",
    "content_dict = {}\n",
    "for i, (index, row) in tqdm(enumerate(contents_df.iterrows())):\n",
    "    text = \"<|content|>\" + f\"<|lang_{row['language']}|>\" + f\"<|kind_{row['kind']}|>\"\n",
    "    text += \"<s_title>\" + row[\"title\"] + \"</s_title>\" + \"<s_description>\" + row[\"description\"] + \"</s_description>\" # + \"<s_text>\" + row[\"text\"] + \"</s_text>\"\n",
    "    content_dict[row[\"id\"]] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2782f1a-36d1-4b5a-89b6-926aeed6541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df[\"topic_text\"] = topic_dict.values()\n",
    "topics_df[\"topic_text\"] = topics_df[\"topic_text\"] # .apply(lambda x: x[:2048])\n",
    "\n",
    "contents_df[\"content_text\"] = content_dict.values()\n",
    "contents_df[\"content_text\"] = contents_df[\"content_text\"] # .apply(lambda x: x[:2048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd58ee0-c996-4b14-9c3b-7d22847dc8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer_name='xlm-roberta-base', max_len=512):\n",
    "        self.texts = texts\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.tokenizer.add_special_tokens(dict(additional_special_tokens=LANGUAGE_TOKENS + CATEGORY_TOKENS + LEVEL_TOKENS + KIND_TOKENS + OTHER_TOKENS))\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        \n",
    "        # topic\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, \n",
    "            return_tensors = None, \n",
    "            add_special_tokens = True, \n",
    "            max_length = self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation = True\n",
    "        )\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "            \n",
    "        return inputs\n",
    "    \n",
    "def collate_fn(inputs):\n",
    "    inputs = default_collate(inputs)\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "        \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09637446-9ae8-4a8b-b60e-629097b0d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dataset = InferenceDataset(texts=list(topics_df.topic_text.values), tokenizer_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2', max_len=128)\n",
    "topic_dataloader = DataLoader(topic_dataset, num_workers=16, batch_size=64, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d32b1-318b-4424-af01-bbf075298558",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Model(tokenizer_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", objective=\"siamese\", is_sentence_transformers=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "weights_path = \"./outputs_siamese/checkpoint-86340/pytorch_model.bin\"\n",
    "\n",
    "state_dict = torch.load(weights_path)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f33aac-6b81-4c11-9855-4e627d36b2ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "topic_embs = []\n",
    "\n",
    "for inputs in tqdm(topic_dataloader):\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k].to(device)\n",
    "    out = model.feature(inputs)\n",
    "    topic_embs.extend(out.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f63849-09ae-43c5-bb5b-1bdbcba33f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_dataset = InferenceDataset(texts=list(contents_df.content_text.values), tokenizer_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2', max_len=128)\n",
    "content_dataloader = DataLoader(content_dataset, num_workers=16, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# # \n",
    "# del contents_df[\"text\"]\n",
    "# del contents_df\n",
    "\n",
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    "content_embs = []\n",
    "\n",
    "for inputs in tqdm(content_dataloader):\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k].to(device)\n",
    "    out = model.feature(inputs)\n",
    "    content_embs.extend(out.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a621519-5667-4375-bfaf-4212315d6330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load from saved files\n",
    "# torch.save(topic_embs, \"./data/topic_embs.pt\")\n",
    "# torch.save(content_embs, \"./data/content_embs.pt\")\n",
    "\n",
    "# # # topic_embs = torch.load(\"./data/topic_embs.pt\")\n",
    "# # # content_embs = torch.load(\"./data/content_embs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7391a5-2bcb-4487-978a-532d6111c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release memory\n",
    "import gc\n",
    "\n",
    "del model\n",
    "del state_dict\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f341bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fuzzywuzzy annoy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1263a349-1632-4ff7-81dc-3b3023767742",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda876a8-cfb2-4697-88d7-e313f3a1669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics = topics_df[topics_df.has_content==True][['id', 'title', 'language']].reset_index(drop=True)\n",
    "\n",
    "topics = topics_df\n",
    "\n",
    "test = topics\n",
    "all_content_ids = contents_df.id.to_numpy()\n",
    "all_content_titles = contents_df.title.to_numpy()\n",
    "all_content_language = contents_df.language.to_numpy()\n",
    "all_test_ids = list(topics.id)\n",
    "all_test_title = list(topics.title)\n",
    "all_test_language = list(test.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744e8833-46a1-494a-a09b-5300a26dde3e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install cuml-cu11 --extra-index-url=https://pypi.ngc.nvidia.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ee0a8-bb64-4def-af7e-a185fffea263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a4a87-2cc8-459d-abe5-6a8162bda6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "from cuml.metrics import pairwise_distances\n",
    "from cuml.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2c56c8-ed96-4e34-9c1e-9ecba6be0505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer predictions to gpu\n",
    "topic_embs_gpu = cp.array(topic_embs)\n",
    "content_embs_gpu = cp.array(content_embs)\n",
    "\n",
    "# Release memory\n",
    "torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "\n",
    "# KNN model\n",
    "print(' ')\n",
    "print('Training KNN model...')\n",
    "neighbors_model = NearestNeighbors(n_neighbors = 2000, metric = 'cosine')\n",
    "neighbors_model.fit(content_embs_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c11f0-55b8-49ea-ab28-6d77f8dacb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = neighbors_model.kneighbors(topic_embs_gpu, return_distance = False)\n",
    "predictions = []\n",
    "for k in tqdm(range(len(indices))):\n",
    "    pred = indices[k]\n",
    "    p = ' '.join([contents_df.loc[ind, 'id'] for ind in pred.get()])\n",
    "    predictions.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd92aa-6dfd-4051-97fd-2dcf1a7e5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_pos_score(y_true, y_pred, top_k):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()[:top_k]))\n",
    "    int_true = np.array([len(x[0] & x[1]) / len(x[0]) for x in zip(y_true, y_pred)])\n",
    "    return round(np.mean(int_true), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63568d74-148b-4a6b-9084-cf6a62a70504",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn_preds = pd.DataFrame({\n",
    "    'topic_id': all_test_ids,\n",
    "    'content_ids': predictions # [\" \".join(p) for p in predictions]\n",
    "}).sort_values(\"topic_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae394d9-0f18-4fb1-8f0e-7fadf99cca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = corrs_df[corrs_df.topic_id.isin(val_topic_ids)].sort_values(\"topic_id\")    \n",
    "for k in [10, 20, 50, 100, 200, 500, 1000, 1500, 2000]:\n",
    "    print(\"top_k =\", k, \"max_score =\", get_pos_score(gt[\"content_ids\"], knn_preds.sort_values(\"topic_id\")[\"content_ids\"], k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b4d203-a366-4ce4-bc9f-8fb4f1ab5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = knn_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c7cac-b779-436b-92ec-ac7e6129678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b834acf9-92c7-44d8-a9cf-d0e1cc42654b",
   "metadata": {},
   "source": [
    "#### get neighbors using annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b7e8f3-67a8-4d9a-8f89-e3d1e9e0894e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ### from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# from annoy import AnnoyIndex\n",
    "\n",
    "\n",
    "# content_forest = AnnoyIndex(content_embs[0].shape[0], metric='angular')\n",
    "# for i, item in tqdm(enumerate(content_embs), total=len(content_embs)):\n",
    "#     content_forest.add_item(i, item)\n",
    "# content_forest.build(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes_dict = {}\n",
    "# fuzzy_dict = {}\n",
    "# classification_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4596424-e963-48fd-8f4a-627e77f82c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: find by distance instead\n",
    "\n",
    "# nearest_content_count = 2000\n",
    "# fuzzy_filter = 80\n",
    "# THRESHOLD = 0\n",
    "# # for fuzzy_filter in range(5, 50, 5):\n",
    "# #     for t in range(1, 10, 2):\n",
    "# #         THRESHOLD = t / 100\n",
    "# preds = []\n",
    "# for i, t_e in tqdm(enumerate(topic_embs), total=len(topic_embs), desc=f'Getting Preds'):\n",
    "#     if i in indexes_dict:\n",
    "#         indexes, distances = indexes_dict[i]\n",
    "#     else:\n",
    "#         indexes, distances = content_forest.get_nns_by_vector(\n",
    "#             # F.normalize(torch.from_numpy(t_e), p=2, dim=0),\n",
    "#             t_e,\n",
    "#             nearest_content_count,\n",
    "#             include_distances=True\n",
    "#         )\n",
    "#         # indexes = [i for i, d in zip(indexes, distances) if d < 10]\n",
    "#         indexes_dict[i] = indexes, distances\n",
    "\n",
    "#     topic_id = all_test_ids[i]\n",
    "#     topic_text = all_test_title[i]\n",
    "#     topic_lang = all_test_language[i]\n",
    "\n",
    "#     # for idx in indexes:\n",
    "#     #     if topic_lang != all_content_language[idx]:\n",
    "#     #         indexes.remove(idx)\n",
    "    \n",
    "#     # filtered_indexes = []\n",
    "#     # for idx in indexes:\n",
    "#     #     if topic_lang != all_content_language[idx]:\n",
    "#     #         continue\n",
    "#     #     if (i, idx) in fuzzy_dict:\n",
    "#     #         fuzzy_value = fuzzy_dict[(i, idx)]\n",
    "#     #     else:\n",
    "#     #         fuzzy_value = fuzz.token_set_ratio(all_content_titles[idx], topic_text)\n",
    "#     #         fuzzy_dict[(i, idx)] = fuzzy_value\n",
    "        \n",
    "#     #     if fuzzy_value > fuzzy_filter:\n",
    "#     #         filtered_indexes.append(idx)\n",
    "        \n",
    "#     #     if (i, idx) in classification_dict:\n",
    "#     #         score = classification_dict[(i, idx)]\n",
    "#     #     else:\n",
    "#     #         topic_features = torch.from_numpy(t_e).to(device)\n",
    "#     #         content_features = torch.from_numpy(content_embs[idx]).to(device)\n",
    "#     #         score = torch.sigmoid(model.fc(torch.cat([topic_features, content_features, topic_features - content_features], -1))).item()\n",
    "#     #         classification_dict[(i, idx)] = score\n",
    "#     #     if score < THRESHOLD and idx in filtered_indexes:\n",
    "#     #         filtered_indexes.remove(idx)\n",
    "#     # ind2dis = {ind: d for ind, d in zip(indexes, distances)}\n",
    "#     # if len(filtered_indexes) == 0:\n",
    "#     #     indexes = filtered_indexes[:8] # list(set(filtered_indexes + indexes[:8-len(filtered_indexes)]))\n",
    "#     # else:\n",
    "#     #     indexes = filtered_indexes[:8]\n",
    "#     content_ids = all_content_ids[indexes]\n",
    "#     preds.append({\n",
    "#         'topic_id': topic_id,\n",
    "#         'content_ids': ' '.join(content_ids),\n",
    "#         # 'distances': ' '.join([str(ind2dis[ind]) for ind in indexes]),\n",
    "#     })\n",
    "# preds = pd.DataFrame.from_records(preds)\n",
    "\n",
    "# preds.to_csv('submission.csv', index=False)\n",
    "\n",
    "# if not TEST_MODE:\n",
    "#     from engine import f2_score\n",
    "#     gt = corrs_df[corrs_df.topic_id.isin(val_topic_ids)].sort_values(\"topic_id\")    \n",
    "#     preds = preds.sort_values(\"topic_id\")    \n",
    "#     print(\"fuzzy_filter\", fuzzy_filter, \"THRESHOLD:\", THRESHOLD, \"f2_score\", f2_score(gt[\"content_ids\"], preds[\"content_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2466ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in [10, 20, 50, 100, 200, 500, 1000, 1500, 2000]:\n",
    "#     print(\"top_k =\", k, \"max_score =\", get_pos_score(gt[\"content_ids\"], preds[\"content_ids\"], k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874af05f-4aeb-4cf3-b46e-1f691ea9c474",
   "metadata": {},
   "source": [
    "### filter by using cross-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56446614-1b16-4b5e-9e0f-deb336f7307f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cross_encoder_model = Model(\n",
    "    tokenizer_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    objective=\"classification\",\n",
    "    is_sentence_transformers=True\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cross_encoder_model = cross_encoder_model.to(device)\n",
    "\n",
    "weights_path = \"./outputs/checkpoint-143900/pytorch_model.bin\"\n",
    "\n",
    "state_dict = torch.load(weights_path)\n",
    "cross_encoder_model.load_state_dict(state_dict)\n",
    "cross_encoder_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c9480-5f67-402e-b106-d66869744fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import init_tokenizer\n",
    "\n",
    "class CrossEncoderDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2', max_len=128):\n",
    "        self.df = df\n",
    "        self.topic_texts = []\n",
    "        self.content_texts = []\n",
    "        for i, row in tqdm(df.iterrows()):\n",
    "            if row[\"content_ids\"]:\n",
    "                for content_id in row[\"content_ids\"].split(\" \"):\n",
    "                    self.topic_texts.append(topic_dict[row[\"topic_id\"]])\n",
    "                    self.content_texts.append(content_dict[content_id])\n",
    "                    \n",
    "        self.tokenizer = init_tokenizer(tokenizer_name)\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.topic_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        topic_text = self.topic_texts[idx]\n",
    "        content_text = self.content_texts[idx]\n",
    "        \n",
    "        # topic\n",
    "        topic_inputs = self.tokenizer.encode_plus(\n",
    "            topic_text, \n",
    "            return_tensors = None, \n",
    "            add_special_tokens = True, \n",
    "            max_length = self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation = True\n",
    "        )\n",
    "        for k, v in topic_inputs.items():\n",
    "            topic_inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "            \n",
    "        # content\n",
    "        content_inputs = self.tokenizer.encode_plus(\n",
    "            content_text, \n",
    "            return_tensors = None, \n",
    "            add_special_tokens = True, \n",
    "            max_length = self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation = True\n",
    "        )\n",
    "        for k, v in content_inputs.items():\n",
    "            content_inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "\n",
    "        combined_inputs = self.tokenizer.encode_plus(\n",
    "            topic_text,\n",
    "            content_text,\n",
    "            return_tensors = None, \n",
    "            add_special_tokens = True, \n",
    "            max_length = self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation = True\n",
    "        )\n",
    "        for k, v in combined_inputs.items():\n",
    "            combined_inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "            \n",
    "        return topic_inputs, content_inputs, combined_inputs, 0\n",
    "\n",
    "\n",
    "def cross_encoder_collate_fn(batch):\n",
    "    batch = default_collate(batch)\n",
    "\n",
    "    topic_inputs, content_inputs, combined_inputs, labels = batch\n",
    "    mask_len = int(topic_inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in topic_inputs.items():\n",
    "        topic_inputs[k] = topic_inputs[k][:,:mask_len]\n",
    "\n",
    "    mask_len = int(content_inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in content_inputs.items():\n",
    "        content_inputs[k] = content_inputs[k][:,:mask_len]\n",
    "\n",
    "    mask_len = int(combined_inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in combined_inputs.items():\n",
    "        combined_inputs[k] = combined_inputs[k][:,:mask_len]\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"topic_inputs\": topic_inputs,\n",
    "        \"content_inputs\": content_inputs,\n",
    "        \"combined_inputs\": combined_inputs,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b7252-5328-48b6-820c-5c5cfac1ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48cf09-b488-4939-87ec-e19a04a7471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = data_df[data_df[\"fold\"] == fold]\n",
    "val_df[\"topic_id\"] = val_df[\"topics_ids\"]\n",
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99177dac-feab-42ba-8b78-6bae5195c30f",
   "metadata": {},
   "source": [
    "##### re-calucate on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa21e6-b151-421a-a0f4-8ecb8fe8d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "ceds = CrossEncoderDataset(val_df, tokenizer_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", max_len=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b897bae6-59de-4383-b6fd-93e0be624cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_dataloader = DataLoader(ceds, batch_size=64, num_workers=16, shuffle=False, collate_fn=cross_encoder_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b65f2b-3214-43b6-b02c-d13b0db66957",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for inputs in tqdm(ce_dataloader):\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k].to(device)\n",
    "    out = cross_encoder_model(**inputs)\n",
    "    out = torch.sigmoid(out)\n",
    "    res.extend(out.cpu().detach().numpy())\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158bdd0-439e-4785-a7dc-c7a7b9d61271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca263eb-fde8-4823-80ed-ce76dc898d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(list(val_df.target.values), [int(r[0] > 0.5) for r in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100acf18-70c5-4157-b89f-75cedcbb9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = val_df.groupby(\"topic_id\", group_keys=False).agg({\"content_ids\": \" \".join})\n",
    "# new_df[\"topic_id\"] = new_df.index\n",
    "# new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11564a94-e09c-4b77-b996-704327f73936",
   "metadata": {},
   "source": [
    "##### calculate on predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc30573-6a23-46f0-9669-c3ad16fafb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ceds = CrossEncoderDataset(preds, tokenizer_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", max_len=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fcd4b3-ab98-4c03-9e27-5bd583bf2e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_dataloader = DataLoader(ceds, batch_size=64, num_workers=16, shuffle=False, collate_fn=cross_encoder_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0fd040-d624-4054-abf0-99253908e929",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for inputs in tqdm(ce_dataloader):\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k].to(device)\n",
    "    out = cross_encoder_model(**inputs)\n",
    "    out = torch.sigmoid(out)\n",
    "    res.extend(out.cpu().detach().numpy())\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0ad058-4a82-4cef-b9fb-abc66b84651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_topics = []\n",
    "pred_contents = []\n",
    "\n",
    "for i, row in tqdm(preds.iterrows()):\n",
    "    if row[\"content_ids\"]:\n",
    "        for content_id in row[\"content_ids\"].split(\" \"):\n",
    "            pred_topics.append(row[\"topic_id\"])\n",
    "            pred_contents.append(content_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a4fd5-7f63-43ce-91cd-a1af2a12a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for topic_id, content_id, score in zip(pred_topics, pred_contents, res):\n",
    "new_pred_df = pd.DataFrame({\n",
    "    \"topic_id\": pred_topics,\n",
    "    \"content_id\": pred_contents,\n",
    "    \"score\": [r[0] for r in res]\n",
    "})\n",
    "\n",
    "new_pred_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23db1b85-ce42-41c8-990a-cd8bd53c8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_df.to_csv(\"prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe825c-4d9c-4a3e-8d35-a1c1738b7b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfefe63-5c85-40c7-b979-6e667047e4de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e27a652-ff7c-4c65-959c-2a90e57e7998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e8510-47a9-4d06-8715-36fdf4c58c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9471c8c-6ef0-442c-b70b-48f16bed7eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6f548-a8f1-4afe-aff8-a3a1be575560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get only positive cases using threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05388962-0892-40a0-a78a-fd2f4b4aefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = new_pred_df\n",
    "# for i in range(30, 100):\n",
    "    # threshold = i / 100\n",
    "threshold = 0.9\n",
    "thresholded_outputs = outputs[outputs[\"score\"] >= threshold].groupby('topic_id').agg({'content_id': \" \".join})\n",
    "# TODO: we need to merge with those topics doesn't have any contents\n",
    "thresholded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adce6118-b5b7-40bc-921b-a8cf6aa99687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0b8ba2-ccdc-4e60-9ab8-9dd479ae5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gt = corrs_df[corrs_df.topic_id.isin(val_topic_ids)].sort_values(\"topic_id\")    \n",
    "thresholded_score = f2_score(gt[\"content_ids\"], thresholded_outputs[\"content_id\"].sort_values(\"topic_id\"))\n",
    "print(\"threshold =\", threshold, \"f2_score =\", thresholded_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd83cb6-a604-49cb-b4c9-b4964f23c69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a2bfb5-1f6d-4dc0-9ce5-99a253ffadc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get top-k, then filter by confidence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb575e1c-ea33-4edc-aed0-1a1c0c78f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 5\n",
    "\n",
    "\n",
    "final_topics = []\n",
    "final_contents = []\n",
    "final_scores = []\n",
    "\n",
    "for i, row in tqdm(new_pred_df.groupby('topic_id').agg({'content_id': \" \".join, \"score\": lambda x: \" \".join([str(e) for e in x])}).iterrows()):\n",
    "    topic_id = i # row[\"topic_id\"]\n",
    "    content_ids = row[\"content_id\"].split(\" \")\n",
    "    # TODO: we can multiply scores and cosine distance to get final score\n",
    "    scores = [float(s) for s in row[\"score\"].split(\" \")]\n",
    "    \n",
    "    data = list(zip(content_ids, scores))\n",
    "    data.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    data = data[:top_k]\n",
    "    content_ids = \" \".join([e[0] for e in data])\n",
    "    scores = \" \".join([e[0] for e in data])\n",
    "    \n",
    "    final_topics.append(i)\n",
    "    final_contents.append(content_ids)\n",
    "    final_scores.append(scores)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7801de35-16a0-45e2-af8e-26e3646e45ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82d0d97-862a-4be8-8e67-bf3c9718a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = pd.DataFrame({\n",
    "    \"topic_id\": final_topics,\n",
    "    \"content_ids\": final_contents\n",
    "})\n",
    "final_preds = final_preds.sort_values(\"topic_id\")    \n",
    "\n",
    "final_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc54531-309d-4856-ab20-1f17eb0f0f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa7791-6edf-46f2-ae6d-3f741cc2b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = corrs_df[corrs_df.topic_id.isin(val_topic_ids)].sort_values(\"topic_id\")    \n",
    "f2_score(gt[\"content_ids\"], final_preds[\"content_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687ef3e9-9f22-4bfa-9f15-af81684bdd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum([len(v.split(\" \")) for v in gt.content_ids.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e3e8ed-033a-4a68-b2a3-9420edd159dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd63ffc-2c80-4fc1-9312-4d4e59cdfd22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904cb7d7-1815-4127-b026-0fae69327778",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e88ec2a-2432-49bc-b6b5-e6da61ca7e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aced63-12de-4b7f-84ea-8a82bfceb0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810cd49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fb070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gt sims\n",
    "# list_all_content_ids = list(all_content_ids)\n",
    "\n",
    "# all_sims = []\n",
    "# for i, row in tqdm(gt.iterrows()):\n",
    "#     sims = []\n",
    "\n",
    "#     t_e = topic_embs[all_test_ids.index(row[\"topic_id\"])]\n",
    "#     for content_id in row[\"content_ids\"].split(\" \"):\n",
    "#         c_e = content_embs[list_all_content_ids.index(content_id)]\n",
    "#         sims.append(cosine_similarity(torch.from_numpy(t_e), torch.from_numpy(c_e), 0))\n",
    "    \n",
    "#     all_sims.append(\" \".join([str(s.item())[:5] for s in sims]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e502243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1228aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prediction sims\n",
    "\n",
    "# list_all_content_ids = list(all_content_ids)\n",
    "\n",
    "# all_preds_sims = []\n",
    "# for i, row in tqdm(preds.iterrows()):\n",
    "#     sims = []\n",
    "\n",
    "#     t_e = topic_embs[all_test_ids.index(row[\"topic_id\"])]\n",
    "#     if not row[\"content_ids\"]:\n",
    "#         continue\n",
    "#     for content_id in row[\"content_ids\"].split(\" \"):\n",
    "#         c_e = content_embs[list_all_content_ids.index(content_id)]\n",
    "#         sims.append(cosine_similarity(torch.from_numpy(t_e), torch.from_numpy(c_e), 0))\n",
    "    \n",
    "#     all_preds_sims.append(\" \".join([str(s.item())[:5] for s in sims]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b988d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_preds_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e9b54f-c4d3-48be-bb7f-80eaa30e3c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# sample_preds = pd.DataFrame({\n",
    "#     \"content_ids\": [\n",
    "#         \"a b c\"\n",
    "#     ]\n",
    "# })\n",
    "\n",
    "# sample_gts = pd.DataFrame({\n",
    "#     \"content_ids\": [\n",
    "#         \"a d e f g h\"\n",
    "#     ]\n",
    "# })\n",
    "# f2_score(\n",
    "#     sample_gts[\"content_ids\"],\n",
    "#     sample_preds[\"content_ids\"],\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
